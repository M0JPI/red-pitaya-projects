{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a95486b5-6fbb-464f-b9de-67fd276282b5",
   "metadata": {},
   "source": [
    "# Audio Classification Using Edge Impulse\n",
    "This example uses audio already recorded from fast analog input IN2 and uses local Edge Impulse Classification to classify 5 seconds of audio.\n",
    "\n",
    "This is based on the Edge Immpulse example:\n",
    "https://github.com/edgeimpulse/linux-sdk-python/blob/master/examples/audio/classify.py \n",
    "\n",
    "The following are required to use the edge_impulse_linux (they can be run from a Jupyter code cell):  \n",
    "`!apt update`\n",
    "\n",
    "`!apt install libatlas-base-dev libportaudio2 libportaudiocpp0 portaudio19-dev python3-opencv`\n",
    "\n",
    "`!apt install libatlas-base-dev libportaudio2 libportaudiocpp0 portaudio19-dev python3-opencv`\n",
    "\n",
    "**Reload the Jupyter kernel** then run:\n",
    "\n",
    "`!pip3 install PyAudio`\n",
    "\n",
    "`!pip3 install edge_impulse_linux`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4347b653-cc9b-4ddb-9843-ca3a76de3c73",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250422a5-24b2-419b-8ae3-5c2e04171356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redpitaya.overlay.mercury import mercury as overlay\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Audio processing requirements\n",
    "import os\n",
    "import sys, getopt\n",
    "import signal\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "#Edge Impulse requirements\n",
    "import json\n",
    "import time, hmac, hashlib\n",
    "import requests\n",
    "import re, socket\n",
    "import math\n",
    "from edge_impulse_linux.runner import ImpulseRunner\n",
    "\n",
    "fpga = overlay()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d38d3-bfb7-48df-a937-118cc236dcb9",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c3b53-913c-420c-bb6d-68b59b8fca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio():\n",
    "    # synchronization and trigger sources are the default,\n",
    "    # which is the module itself\n",
    "    in2.reset()\n",
    "    in2.start()\n",
    "    in2.trigger()\n",
    "    print ('Recording started')\n",
    "    # wait for data\n",
    "    while (in2.status_run()): pass\n",
    "    print ('Recording complete')\n",
    "    data = in2.data(N)\n",
    "    return data[1:] #Remove first sample as it maybe zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255ff54-e663-4c7d-935f-0413d5b92c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_audio(audio_data,sr = 3000): #default sample rate 3 Ksps\n",
    "    return ipd.Audio(audio_data, rate=sr) # load a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1c9c8-84a8-4382-a162-0448e6fdd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio(audio_data):\n",
    "    # show the part of the buffer requested by pre/post trigger timing - in this example the whole buffer.\n",
    "    plt.plot(audio_data_returned)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aedb82-0f48-41ea-8dbc-7e8eacc070de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_audio(audio_data, file='float_wave_test_raw.wav', sr = 3000): #default sample rate 3 Ksps\n",
    "    wavfile.write(file, sr, audio_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849383f-8f53-4769-bd9d-f08d6c0d7369",
   "metadata": {},
   "source": [
    "## Setup Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd7274-6414-4ec5-bbb0-e2e4bf596e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "in2 = fpga.osc(1, 1.0)\n",
    "# data rate decimation \n",
    "in2.decimation = 41667 #125 Msps / 41667 = 30 Ksps\n",
    "\n",
    "# trigger timing [sample periods]\n",
    "N = in2.buffer_size\n",
    "in2.trigger_pre  = 0\n",
    "in2.trigger_post = N\n",
    "\n",
    "# disable hardware trigger sources - the Jupyter notebook will trigger the start of audio recording\n",
    "in2.trig_src = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65005057-2354-41f3-a2db-9f48ba1f8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = None\n",
    "model_file_name = 'modelfile.eim'\n",
    "audio_file_name = 'float_wave_test_raw.wav'\n",
    "\n",
    "dir_path = os.path.dirname(os.path.realpath(model_file_name))\n",
    "modelfile = os.path.join(dir_path, model_file_name)\n",
    "audio_file = os.path.join(dir_path, audio_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71697e36-b7c7-47f5-bf95-8cb8f002b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate, generator = wavfile.read(audio_file)\n",
    "\n",
    "features = np.array([], dtype=np.int16)\n",
    "runner = ImpulseRunner(modelfile)\n",
    "\n",
    "model_info = runner.init()\n",
    "labels = model_info['model_parameters']['labels']\n",
    "window_size = model_info['model_parameters']['input_features_count']\n",
    "sampling_rate = model_info['model_parameters']['frequency']\n",
    "print('Loaded runner for \"' + model_info['project']['owner'] + ' / ' + model_info['project']['name'] + '\"')\n",
    "print('labels: ', labels)\n",
    "print('window_size: ', window_size)\n",
    "print('sampling_rate: ', sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e7c8e-9e75-43e6-ae72-a4e7873cb27e",
   "metadata": {},
   "source": [
    "## Recording the Audio and Classifying it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d35d68-86ad-43ac-9a51-3bd15f5fa7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data_returned = record_audio()\n",
    "save_audio(audio_data_returned, sr = 3000)\n",
    "\n",
    "samplerate, generator = wavfile.read(audio_file)\n",
    "features = np.array([], dtype=np.int16) #Reset features\n",
    "features = np.concatenate((features, generator), axis=0)\n",
    "\n",
    "#Reset the runner\n",
    "runner = None\n",
    "runner = ImpulseRunner(modelfile)\n",
    "model_info = runner.init()\n",
    "res = runner.classify(features[:window_size].tolist())\n",
    "\n",
    "#Show the classification key that has the highest confidence index\n",
    "best_label = max(res['result']['classification'], key=lambda key: res['result']['classification'][key])\n",
    "confidence = res['result']['classification'][best_label]\n",
    "print(best_label,\"{:.2%}\".format(confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161e885-9959-42d8-900d-58f3681d3e99",
   "metadata": {},
   "source": [
    "## Classification Detailed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f330635-a1a2-4d1c-9ef2-e0075fe92aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5a1e4-5271-427f-a3e7-16e7160f0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Result (%d ms.) ' % (res['timing']['dsp'] + res['timing']['classification']), end='')\n",
    "for label in labels:\n",
    "    score = res['result']['classification'][label]\n",
    "    print('%s: %.2f\\t' % (label, score), end='')\n",
    "    print('', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd4a2d9-2d6f-485b-a83f-bc565ed38f79",
   "metadata": {},
   "source": [
    "## Display the Audio Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54890e03-1509-4986-888f-9890b5f39c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio(audio_data_returned)\n",
    "display_audio(audio_data_returned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (RP api)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
